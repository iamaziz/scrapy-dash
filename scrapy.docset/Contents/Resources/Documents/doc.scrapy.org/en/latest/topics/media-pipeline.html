

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->

<!-- Mirrored from doc.scrapy.org/en/latest/topics/media-pipeline.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 08 Sep 2015 15:33:20 GMT -->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Downloading and processing files and images &mdash; Scrapy 1.0.3 documentation</title>
  

  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="../../../../media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="../../../../media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  

  
    <link rel="top" title="Scrapy 1.0.3 documentation" href="../index-2.html"/>
        <link rel="next" title="Ubuntu packages" href="ubuntu.html"/>
        <link rel="prev" title="Debugging memory leaks" href="leaks.html"/>
 
<!-- RTD Extra Head -->



  
  <!-- 
  Always link to the latest version, as canonical.
  http://docs.readthedocs.org/en/latest/canonical.html
  -->
  <link rel="canonical" href="media-pipeline.html" />
  

<script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy",
    version: "latest",
    language: "en",
    page: "topics/media-pipeline",
    builder: "sphinx",
    theme: "sphinx_rtd_theme",
    docroot: "/docs/",
    
    source_suffix: ".rst",
    
    api_host: "https://readthedocs.org/",
    commit: "2d688cd94d8be79da265f330c64c6994952d32c2"
  }
  // Old variables
  var doc_version = "latest";
  var doc_slug = "scrapy";
  var page_name = "topics/media-pipeline";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);

  // User Analytics Code
  _gaq.push(['user._setAccount', 'UA-10231918-2']);
  _gaq.push(['user._trackPageview']);
  // End User Analytics Code


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        

        
          <a href="../index-2.html" class="icon icon-home"> Scrapy
        

        
        </a>

        
          
          
          
            <div class="version">
              latest
            </div>
          
        

        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="http://doc.scrapy.org/en/latest/search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">Scrapy at a glance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">Installation guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="commands.html">Command line tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">Selectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a></li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a></li>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a></li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a></li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">Exceptions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">Stats Collection</a></li>
<li class="toctree-l1"><a class="reference internal" href="email.html">Sending e-mail</a></li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet Console</a></li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a></li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">Common Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">Broad Crawls</a></li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">Using Firefox for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">Using Firebug for scraping</a></li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">Debugging memory leaks</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Downloading and processing files and images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#using-the-files-pipeline">Using the Files Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-the-images-pipeline">Using the Images Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#usage-example">Usage example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#enabling-your-media-pipeline">Enabling your Media Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#supported-storage">Supported Storage</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#file-system-storage">File system storage</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#additional-features">Additional features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#file-expiration">File expiration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#thumbnail-generation-for-images">Thumbnail generation for images</a></li>
<li class="toctree-l3"><a class="reference internal" href="#filtering-out-small-images">Filtering out small images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-scrapy.pipelines.files">Extending the Media Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-images-pipeline-example">Custom Images pipeline example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">Deploying Spiders</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">AutoThrottle extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: pausing and resuming crawls</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">Architecture overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">Downloader Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider Middleware</a></li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Core API</a></li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">Signals</a></li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a></li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index-2.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index-2.html">Docs</a> &raquo;</li>
      
    <li>Downloading and processing files and images</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="https://github.com/scrapy/scrapy/blob/1.0/docs/topics/media-pipeline.rst" class="fa fa-github"> Edit on GitHub</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="downloading-and-processing-files-and-images">
<span id="topics-media-pipeline"></span><h1>Downloading and processing files and images<a class="headerlink" href="#downloading-and-processing-files-and-images" title="Permalink to this headline">¶</a></h1>
<p>Scrapy provides reusable <a class="reference internal" href="item-pipeline.html"><em>item pipelines</em></a> for
downloading fies attached to a particular item (for example, when you scrape
products and also want to download their images locally). These pipelines share
a bit of functionality and structure (we refer to them as media pipelines), but
typically you&#8217;ll either use the Files Pipeline or the Images Pipeline.</p>
<p>Both pipelines implement these features:</p>
<ul class="simple">
<li>Avoid re-downloading media that was downloaded recently</li>
<li>Specifying where to store the media (filesystem directory, Amazon S3 bucket)</li>
</ul>
<p>The Images Pipeline has a few extra functions for processing images:</p>
<ul class="simple">
<li>Convert all downloaded images to a common format (JPG) and mode (RGB)</li>
<li>Thumbnail generation</li>
<li>Check images width/height to make sure they meet a minimum constraint</li>
</ul>
<p>The pipelines also keep an internal queue of those media URLs which are currently
being scheduled for download, and connect those responses that arrive containing
the same media to that queue. This avoids downloading the same media more than
once when it&#8217;s shared by several items.</p>
<div class="section" id="using-the-files-pipeline">
<h2>Using the Files Pipeline<a class="headerlink" href="#using-the-files-pipeline" title="Permalink to this headline">¶</a></h2>
<p>The typical workflow, when using the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code> goes like
this:</p>
<ol class="arabic simple">
<li>In a Spider, you scrape an item and put the URLs of the desired into a
<code class="docutils literal"><span class="pre">file_urls</span></code> field.</li>
<li>The item is returned from the spider and goes to the item pipeline.</li>
<li>When the item reaches the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code>, the URLs in the
<code class="docutils literal"><span class="pre">file_urls</span></code> field are scheduled for download using the standard
Scrapy scheduler and downloader (which means the scheduler and downloader
middlewares are reused), but with a higher priority, processing them before other
pages are scraped. The item remains &#8220;locked&#8221; at that particular pipeline stage
until the files have finish downloading (or fail for some reason).</li>
<li>When the files are downloaded, another field (<code class="docutils literal"><span class="pre">files</span></code>) will be populated
with the results. This field will contain a list of dicts with information
about the downloaded files, such as the downloaded path, the original
scraped url (taken from the <code class="docutils literal"><span class="pre">file_urls</span></code> field) , and the file checksum.
The files in the list of the <code class="docutils literal"><span class="pre">files</span></code> field will retain the same order of
the original <code class="docutils literal"><span class="pre">file_urls</span></code> field. If some file failed downloading, an
error will be logged and the file won&#8217;t be present in the <code class="docutils literal"><span class="pre">files</span></code> field.</li>
</ol>
</div>
<div class="section" id="using-the-images-pipeline">
<h2>Using the Images Pipeline<a class="headerlink" href="#using-the-images-pipeline" title="Permalink to this headline">¶</a></h2>
<p>Using the <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline" title="scrapy.pipelines.images.ImagesPipeline"><code class="xref py py-class docutils literal"><span class="pre">ImagesPipeline</span></code></a> is a lot like using the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code>,
except the default field names used are different: you use <code class="docutils literal"><span class="pre">image_urls</span></code> for
the image URLs of an item and it will populate an <code class="docutils literal"><span class="pre">images</span></code> field for the information
about the downloaded images.</p>
<p>The advantage of using the <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline" title="scrapy.pipelines.images.ImagesPipeline"><code class="xref py py-class docutils literal"><span class="pre">ImagesPipeline</span></code></a> for image files is that you
can configure some extra functions like generating thumbnails and filtering
the images based on their size.</p>
<p>The Images Pipeline uses <a class="reference external" href="https://github.com/python-pillow/Pillow">Pillow</a> for thumbnailing and normalizing images to
JPEG/RGB format, so you need to install this library in order to use it.
<a class="reference external" href="http://www.pythonware.com/products/pil/">Python Imaging Library</a> (PIL) should also work in most cases, but it is known
to cause troubles in some setups, so we recommend to use <a class="reference external" href="https://github.com/python-pillow/Pillow">Pillow</a> instead of
PIL.</p>
</div>
<div class="section" id="usage-example">
<h2>Usage example<a class="headerlink" href="#usage-example" title="Permalink to this headline">¶</a></h2>
<p>In order to use a media pipeline first, <a class="reference internal" href="#topics-media-pipeline-enabling"><span>enable it</span></a>.</p>
<p>Then, if a spider returns a dict with the URLs key (&#8216;file_urls&#8217; or
&#8216;image_urls&#8217;, for the Files or Images Pipeline respectively), the pipeline will
put the results under respective key (&#8216;files&#8217; or images&#8217;).</p>
<p>If you prefer to use <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><code class="xref py py-class docutils literal"><span class="pre">Item</span></code></a>, then define a custom item with the
necessary fields, like in this example for Images Pipeline:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scrapy</span>

<span class="k">class</span> <span class="nc">MyItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>

    <span class="c"># ... other item fields ...</span>
    <span class="n">image_urls</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre></div>
</div>
<p>If you need something more complex and want to override the custom pipeline
behaviour, see <a class="reference internal" href="#topics-media-pipeline-override"><span>Extending the Media Pipelines</span></a>.</p>
</div>
<div class="section" id="enabling-your-media-pipeline">
<span id="topics-media-pipeline-enabling"></span><h2>Enabling your Media Pipeline<a class="headerlink" href="#enabling-your-media-pipeline" title="Permalink to this headline">¶</a></h2>
<span class="target" id="std:setting-IMAGES_STORE"></span><p id="std:setting-FILES_STORE">To enable your media pipeline you must first add it to your project
<a class="reference internal" href="settings.html#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> setting.</p>
<p>For Images Pipeline, use:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;scrapy.pipelines.images.ImagesPipeline&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
</pre></div>
</div>
<p>For Files Pipeline, use:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;scrapy.pipelines.files.FilesPipeline&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can also use both the Files and Images Pipeline at the same time.</p>
</div>
<p>Then, configure the target storage setting to a valid value that will be used
for storing the downloaded images. Otherwise the pipeline will remain disabled,
even if you include it in the <a class="reference internal" href="settings.html#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> setting.</p>
<p>For the Files Pipeline, set the <a class="reference internal" href="#std:setting-FILES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">FILES_STORE</span></code></a> setting:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">FILES_STORE</span> <span class="o">=</span> <span class="s">&#39;/path/to/valid/dir&#39;</span>
</pre></div>
</div>
<p>For the Images Pipeline, set the <a class="reference internal" href="#std:setting-IMAGES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE</span></code></a> setting:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">IMAGES_STORE</span> <span class="o">=</span> <span class="s">&#39;/path/to/valid/dir&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="supported-storage">
<h2>Supported Storage<a class="headerlink" href="#supported-storage" title="Permalink to this headline">¶</a></h2>
<p>File system is currently the only officially supported storage, but there is
also (undocumented) support for storing files in <a class="reference external" href="http://aws.amazon.com/s3/">Amazon S3</a>.</p>
<div class="section" id="file-system-storage">
<h3>File system storage<a class="headerlink" href="#file-system-storage" title="Permalink to this headline">¶</a></h3>
<p>The files are stored using a <a class="reference external" href="http://en.wikipedia.org/wiki/SHA_hash_functions">SHA1 hash</a> of their URLs for the file names.</p>
<p>For example, the following image URL:</p>
<div class="highlight-python"><div class="highlight"><pre>http://www.example.com/image.jpg
</pre></div>
</div>
<p>Whose <cite>SHA1 hash</cite> is:</p>
<div class="highlight-python"><div class="highlight"><pre>3afec3b4765f8f0a07b78f98c07b83f013567a0a
</pre></div>
</div>
<p>Will be downloaded and stored in the following file:</p>
<div class="highlight-python"><div class="highlight"><pre>&lt;IMAGES_STORE&gt;/full/3afec3b4765f8f0a07b78f98c07b83f013567a0a.jpg
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">&lt;IMAGES_STORE&gt;</span></code> is the directory defined in <a class="reference internal" href="#std:setting-IMAGES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_STORE</span></code></a> setting
for the Images Pipeline.</li>
<li><code class="docutils literal"><span class="pre">full</span></code> is a sub-directory to separate full images from thumbnails (if
used). For more info see <a class="reference internal" href="#topics-images-thumbnails"><span>Thumbnail generation for images</span></a>.</li>
</ul>
</div>
</div>
<div class="section" id="additional-features">
<h2>Additional features<a class="headerlink" href="#additional-features" title="Permalink to this headline">¶</a></h2>
<div class="section" id="file-expiration">
<h3>File expiration<a class="headerlink" href="#file-expiration" title="Permalink to this headline">¶</a></h3>
<span class="target" id="std:setting-IMAGES_EXPIRES"></span><p id="std:setting-FILES_EXPIRES">The Image Pipeline avoids downloading files that were downloaded recently. To
adjust this retention delay use the <a class="reference internal" href="#std:setting-FILES_EXPIRES"><code class="xref std std-setting docutils literal"><span class="pre">FILES_EXPIRES</span></code></a> setting (or
<a class="reference internal" href="#std:setting-IMAGES_EXPIRES"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_EXPIRES</span></code></a>, in case of Images Pipeline), which
specifies the delay in number of days:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c"># 90 days of delay for files expiration</span>
<span class="n">FILES_EXPIRES</span> <span class="o">=</span> <span class="mi">90</span>

<span class="c"># 30 days of delay for images expiration</span>
<span class="n">IMAGES_EXPIRES</span> <span class="o">=</span> <span class="mi">30</span>
</pre></div>
</div>
</div>
<div class="section" id="thumbnail-generation-for-images">
<span id="topics-images-thumbnails"></span><h3>Thumbnail generation for images<a class="headerlink" href="#thumbnail-generation-for-images" title="Permalink to this headline">¶</a></h3>
<p>The Images Pipeline can automatically create thumbnails of the downloaded
images.</p>
<p id="std:setting-IMAGES_THUMBS">In order use this feature, you must set <a class="reference internal" href="#std:setting-IMAGES_THUMBS"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_THUMBS</span></code></a> to a dictionary
where the keys are the thumbnail names and the values are their dimensions.</p>
<p>For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">IMAGES_THUMBS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;small&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
    <span class="s">&#39;big&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">270</span><span class="p">,</span> <span class="mi">270</span><span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
<p>When you use this feature, the Images Pipeline will create thumbnails of the
each specified size with this format:</p>
<div class="highlight-python"><div class="highlight"><pre>&lt;IMAGES_STORE&gt;/thumbs/&lt;size_name&gt;/&lt;image_id&gt;.jpg
</pre></div>
</div>
<p>Where:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">&lt;size_name&gt;</span></code> is the one specified in the <a class="reference internal" href="#std:setting-IMAGES_THUMBS"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_THUMBS</span></code></a>
dictionary keys (<code class="docutils literal"><span class="pre">small</span></code>, <code class="docutils literal"><span class="pre">big</span></code>, etc)</li>
<li><code class="docutils literal"><span class="pre">&lt;image_id&gt;</span></code> is the <a class="reference external" href="http://en.wikipedia.org/wiki/SHA_hash_functions">SHA1 hash</a> of the image url</li>
</ul>
<p>Example of image files stored using <code class="docutils literal"><span class="pre">small</span></code> and <code class="docutils literal"><span class="pre">big</span></code> thumbnail names:</p>
<div class="highlight-python"><div class="highlight"><pre>&lt;IMAGES_STORE&gt;/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
&lt;IMAGES_STORE&gt;/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
&lt;IMAGES_STORE&gt;/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg
</pre></div>
</div>
<p>The first one is the full image, as downloaded from the site.</p>
</div>
<div class="section" id="filtering-out-small-images">
<h3>Filtering out small images<a class="headerlink" href="#filtering-out-small-images" title="Permalink to this headline">¶</a></h3>
<span class="target" id="std:setting-IMAGES_MIN_HEIGHT"></span><p id="std:setting-IMAGES_MIN_WIDTH">When using the Images Pipeline, you can drop images which are too small, by
specifying the minimum allowed size in the <a class="reference internal" href="#std:setting-IMAGES_MIN_HEIGHT"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_MIN_HEIGHT</span></code></a> and
<a class="reference internal" href="#std:setting-IMAGES_MIN_WIDTH"><code class="xref std std-setting docutils literal"><span class="pre">IMAGES_MIN_WIDTH</span></code></a> settings.</p>
<p>For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">IMAGES_MIN_HEIGHT</span> <span class="o">=</span> <span class="mi">110</span>
<span class="n">IMAGES_MIN_WIDTH</span> <span class="o">=</span> <span class="mi">110</span>
</pre></div>
</div>
<p>Note: these size constraints don&#8217;t affect thumbnail generation at all.</p>
<p>By default, there are no size constraints, so all images are processed.</p>
</div>
</div>
<div class="section" id="module-scrapy.pipelines.files">
<span id="extending-the-media-pipelines"></span><span id="topics-media-pipeline-override"></span><h2>Extending the Media Pipelines<a class="headerlink" href="#module-scrapy.pipelines.files" title="Permalink to this headline">¶</a></h2>
<p>See here the methods that you can override in your custom Files Pipeline:</p>
<dl class="class">
<dt id="scrapy.pipelines.files.FilesPipeline">
<em class="property">class </em><code class="descclassname">scrapy.pipelines.files.</code><code class="descname">FilesPipeline</code><a class="headerlink" href="#scrapy.pipelines.files.FilesPipeline" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="scrapy.pipelines.files.FilesPipeline.get_media_requests">
<code class="descname">get_media_requests</code><span class="sig-paren">(</span><em>item</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="Permalink to this definition">¶</a></dt>
<dd><p>As seen on the workflow, the pipeline will get the URLs of the images to
download from the item. In order to do this, you can override the
<a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a> method and return a Request for each
file URL:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">get_media_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">file_url</span> <span class="ow">in</span> <span class="n">item</span><span class="p">[</span><span class="s">&#39;file_urls&#39;</span><span class="p">]:</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">file_url</span><span class="p">)</span>
</pre></div>
</div>
<p>Those requests will be processed by the pipeline and, when they have finished
downloading, the results will be sent to the
<a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method, as a list of 2-element tuples.
Each tuple will contain <code class="docutils literal"><span class="pre">(success,</span> <span class="pre">file_info_or_error)</span></code> where:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">success</span></code> is a boolean which is <code class="docutils literal"><span class="pre">True</span></code> if the image was downloaded
successfully or <code class="docutils literal"><span class="pre">False</span></code> if it failed for some reason</li>
<li><code class="docutils literal"><span class="pre">file_info_or_error</span></code> is a dict containing the following keys (if success
is <code class="docutils literal"><span class="pre">True</span></code>) or a <a class="reference external" href="http://twistedmatrix.com/documents/current/api/twisted.python.failure.Failure.html">Twisted Failure</a> if there was a problem.<ul>
<li><code class="docutils literal"><span class="pre">url</span></code> - the url where the file was downloaded from. This is the url of
the request returned from the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a>
method.</li>
<li><code class="docutils literal"><span class="pre">path</span></code> - the path (relative to <a class="reference internal" href="#std:setting-FILES_STORE"><code class="xref std std-setting docutils literal"><span class="pre">FILES_STORE</span></code></a>) where the file
was stored</li>
<li><code class="docutils literal"><span class="pre">checksum</span></code> - a <a class="reference external" href="http://en.wikipedia.org/wiki/MD5">MD5 hash</a> of the image contents</li>
</ul>
</li>
</ul>
<p>The list of tuples received by <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> is
guaranteed to retain the same order of the requests returned from the
<a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a> method.</p>
<p>Here&#8217;s a typical value of the <code class="docutils literal"><span class="pre">results</span></code> argument:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">[(</span><span class="bp">True</span><span class="p">,</span>
  <span class="p">{</span><span class="s">&#39;checksum&#39;</span><span class="p">:</span> <span class="s">&#39;2b00042f7481c7b056c4b410d28f33cf&#39;</span><span class="p">,</span>
   <span class="s">&#39;path&#39;</span><span class="p">:</span> <span class="s">&#39;full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg&#39;</span><span class="p">,</span>
   <span class="s">&#39;url&#39;</span><span class="p">:</span> <span class="s">&#39;http://www.example.com/files/product1.pdf&#39;</span><span class="p">}),</span>
 <span class="p">(</span><span class="bp">False</span><span class="p">,</span>
  <span class="n">Failure</span><span class="p">(</span><span class="o">...</span><span class="p">))]</span>
</pre></div>
</div>
<p>By default the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.get_media_requests" title="scrapy.pipelines.files.FilesPipeline.get_media_requests"><code class="xref py py-meth docutils literal"><span class="pre">get_media_requests()</span></code></a> method returns <code class="docutils literal"><span class="pre">None</span></code> which
means there are no files to download for the item.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.pipelines.files.FilesPipeline.item_completed">
<code class="descname">item_completed</code><span class="sig-paren">(</span><em>results</em>, <em>items</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">FilesPipeline.item_completed()</span></code></a> method called when all file
requests for a single item have completed (either finished downloading, or
failed for some reason).</p>
<p>The <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method must return the
output that will be sent to subsequent item pipeline stages, so you must
return (or drop) the item, as you would in any pipeline.</p>
<p>Here is an example of the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method where we
store the downloaded file paths (passed in results) in the <code class="docutils literal"><span class="pre">file_paths</span></code>
item field, and we drop the item if it doesn&#8217;t contain any files:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.exceptions</span> <span class="kn">import</span> <span class="n">DropItem</span>

<span class="k">def</span> <span class="nf">item_completed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="n">file_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s">&#39;path&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">ok</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">ok</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">file_paths</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">DropItem</span><span class="p">(</span><span class="s">&quot;Item contains no files&quot;</span><span class="p">)</span>
    <span class="n">item</span><span class="p">[</span><span class="s">&#39;file_paths&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">file_paths</span>
    <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>By default, the <a class="reference internal" href="#scrapy.pipelines.files.FilesPipeline.item_completed" title="scrapy.pipelines.files.FilesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method returns the item.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-scrapy.pipelines.images"></span><p>See here the methods that you can override in your custom Images Pipeline:</p>
<dl class="class">
<dt id="scrapy.pipelines.images.ImagesPipeline">
<em class="property">class </em><code class="descclassname">scrapy.pipelines.images.</code><code class="descname">ImagesPipeline</code><a class="headerlink" href="#scrapy.pipelines.images.ImagesPipeline" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div>The <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline" title="scrapy.pipelines.images.ImagesPipeline"><code class="xref py py-class docutils literal"><span class="pre">ImagesPipeline</span></code></a> is an extension of the <code class="xref py py-class docutils literal"><span class="pre">FilesPipeline</span></code>,
customizing the field names and adding custom behavior for images.</div></blockquote>
<dl class="method">
<dt id="scrapy.pipelines.images.ImagesPipeline.get_media_requests">
<code class="descname">get_media_requests</code><span class="sig-paren">(</span><em>item</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.images.ImagesPipeline.get_media_requests" title="Permalink to this definition">¶</a></dt>
<dd><p>Works the same way as <code class="xref py py-meth docutils literal"><span class="pre">FilesPipeline.get_media_requests()</span></code> method,
but using a different field name for image urls.</p>
<p>Must return a Request for each image URL.</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.pipelines.images.ImagesPipeline.item_completed">
<code class="descname">item_completed</code><span class="sig-paren">(</span><em>results</em>, <em>items</em>, <em>info</em><span class="sig-paren">)</span><a class="headerlink" href="#scrapy.pipelines.images.ImagesPipeline.item_completed" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline.item_completed" title="scrapy.pipelines.images.ImagesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">ImagesPipeline.item_completed()</span></code></a> method is called when all image
requests for a single item have completed (either finished downloading, or
failed for some reason).</p>
<p>Works the same way as <code class="xref py py-meth docutils literal"><span class="pre">FilesPipeline.item_completed()</span></code> method,
but using a different field names for storing image downloading results.</p>
<p>By default, the <a class="reference internal" href="#scrapy.pipelines.images.ImagesPipeline.item_completed" title="scrapy.pipelines.images.ImagesPipeline.item_completed"><code class="xref py py-meth docutils literal"><span class="pre">item_completed()</span></code></a> method returns the item.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="custom-images-pipeline-example">
<h2>Custom Images pipeline example<a class="headerlink" href="#custom-images-pipeline-example" title="Permalink to this headline">¶</a></h2>
<p>Here is a full example of the Images Pipeline whose methods are examplified
above:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">scrapy.pipelines.images</span> <span class="kn">import</span> <span class="n">ImagesPipeline</span>
<span class="kn">from</span> <span class="nn">scrapy.exceptions</span> <span class="kn">import</span> <span class="n">DropItem</span>

<span class="k">class</span> <span class="nc">MyImagesPipeline</span><span class="p">(</span><span class="n">ImagesPipeline</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">get_media_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">image_url</span> <span class="ow">in</span> <span class="n">item</span><span class="p">[</span><span class="s">&#39;image_urls&#39;</span><span class="p">]:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">image_url</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">item_completed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
        <span class="n">image_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s">&#39;path&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">ok</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">ok</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">image_paths</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">DropItem</span><span class="p">(</span><span class="s">&quot;Item contains no images&quot;</span><span class="p">)</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;image_paths&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_paths</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ubuntu.html" class="btn btn-neutral float-right" title="Ubuntu packages" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="leaks.html" class="btn btn-neutral" title="Debugging memory leaks" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2008-2015, Scrapy developers.
      
        <span class="commit">
          Revision <code>2d688cd94d8be79da265f330c64c6994952d32c2</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org/">Read the Docs</a>.

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="../index.html">latest</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/stable/">stable</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/master/">master</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/1.0/">1.0</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.24/">0.24</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.22/">0.22</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.20/">0.20</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.18/">0.18</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.16/">0.16</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.14/">0.14</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.12/">0.12</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.10.3/">0.10.3</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.9/">0.9</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.8/">0.8</a></dd>
        
          <dd><a href="http://doc.scrapy.org/en/0.7/">0.7</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="http://readthedocs.org/projects/scrapy/downloads/pdf/latest/">pdf</a></dd>
        
          <dd><a href="http://readthedocs.org/projects/scrapy/downloads/htmlzip/latest/">htmlzip</a></dd>
        
          <dd><a href="http://readthedocs.org/projects/scrapy/downloads/epub/latest/">epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="http://readthedocs.org/projects/scrapy/?fromdocs=scrapy">Project Home</a>
          </dd>
          <dd>
            <a href="http://readthedocs.org/builds/scrapy/?fromdocs=scrapy">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org/">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0.3',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="../../../../media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>

<!-- Mirrored from doc.scrapy.org/en/latest/topics/media-pipeline.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 08 Sep 2015 15:33:20 GMT -->
</html>